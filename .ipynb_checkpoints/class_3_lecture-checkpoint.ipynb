{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trafilatura in /opt/anaconda3/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: bs4 in /opt/anaconda3/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: fitz in /opt/anaconda3/lib/python3.12/site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: pytesseract in /opt/anaconda3/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: surya-ocr in /opt/anaconda3/lib/python3.12/site-packages (0.14.7)\n",
      "Requirement already satisfied: faster-whisper in /opt/anaconda3/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: openai-whisper in /opt/anaconda3/lib/python3.12/site-packages (20250625)\n",
      "Requirement already satisfied: datasketch in /opt/anaconda3/lib/python3.12/site-packages (1.6.5)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (2025.1.31)\n",
      "Requirement already satisfied: charset_normalizer>=3.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (3.4.1)\n",
      "Requirement already satisfied: courlan>=1.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (1.3.2)\n",
      "Requirement already satisfied: htmldate>=1.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (1.9.3)\n",
      "Requirement already satisfied: justext>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (3.0.2)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (5.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: configobj in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (5.0.9)\n",
      "Requirement already satisfied: configparser in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (7.2.0)\n",
      "Requirement already satisfied: httplib2 in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (5.3.2)\n",
      "Requirement already satisfied: nipype in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (1.10.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (2.0.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (2.3.1)\n",
      "Requirement already satisfied: pyxnat in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (1.6.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from fitz) (1.16.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.12/site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.8 in /Users/pc/.local/lib/python3.12/site-packages (from surya-ocr) (8.1.8)\n",
      "Requirement already satisfied: einops<0.9.0,>=0.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (0.8.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (1.2.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.11.0.86 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (4.12.0.88)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.6 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (4.3.8)\n",
      "Requirement already satisfied: pre-commit<5.0.0,>=4.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (4.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (2.10.6)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (2.10.1)\n",
      "Requirement already satisfied: pypdfium2==4.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (4.30.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (1.1.1)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (2.7.1)\n",
      "Requirement already satisfied: transformers<4.54.0,>=4.51.2 in /opt/anaconda3/lib/python3.12/site-packages (from surya-ocr) (4.53.3)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /opt/anaconda3/lib/python3.12/site-packages (from faster-whisper) (4.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from faster-whisper) (0.34.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from faster-whisper) (0.21.0)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /opt/anaconda3/lib/python3.12/site-packages (from faster-whisper) (1.22.0)\n",
      "Requirement already satisfied: av>=11 in /opt/anaconda3/lib/python3.12/site-packages (from faster-whisper) (15.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from faster-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (10.6.0)\n",
      "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: babel>=2.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
      "Requirement already satisfied: tld>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.1.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /opt/anaconda3/lib/python3.12/site-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster-whisper) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster-whisper) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster-whisper) (1.1.5)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (2.6.12)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (20.31.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (2.27.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.1.0->surya-ocr) (0.4.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<4.54.0,>=4.51.2->surya-ocr) (2025.7.34)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<4.54.0,>=4.51.2->surya-ocr) (0.5.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from httplib2->fitz) (3.2.0)\n",
      "Requirement already satisfied: prov>=1.5.2 in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (2.1.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (4.0.1)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (7.1.4)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (7.0.2)\n",
      "Requirement already satisfied: acres in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (0.5.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: puremagic in /opt/anaconda3/lib/python3.12/site-packages (from nipype->fitz) (1.30)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->fitz) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->fitz) (2024.2)\n",
      "Requirement already satisfied: pathlib>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /opt/anaconda3/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in /opt/anaconda3/lib/python3.12/site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: lxml_html_clean in /opt/anaconda3/lib/python3.12/site-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit<5.0.0,>=4.2.0->surya-ocr) (0.4.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pc/.local/lib/python3.12/site-packages (from jinja2->torch<3.0.0,>=2.7.0->surya-ocr) (3.0.2)\n",
      "\u001b[33mWarning:\u001b[0m ffmpeg 7.1.1_3 is already installed and up-to-date.\n",
      "To reinstall 7.1.1_3, run:\n",
      "  brew reinstall ffmpeg\n"
     ]
    }
   ],
   "source": [
    "! pip3 install trafilatura requests bs4 fitz pytesseract pillow surya-ocr faster-whisper openai-whisper datasketch\n",
    "\n",
    "# install ffmpg for Whisper to process your audio\n",
    "# On macOS (with Homebrew)\n",
    "! brew install ffmpeg\n",
    "#On Ubuntu/Debian:\n",
    "# ! sudo apt-get update -y\n",
    "# ! sudo apt-get install -y ffmpeg\n",
    "# 👉 On Windows (if using WSL or native):\n",
    "# You can download it from:\n",
    "# 🔗 https://ffmpeg.org/download.html\n",
    "# Or use a package manager like Chocolatey:\n",
    "# ! choco install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Pretraining Data Collection & Extraction - Hands-on Notebook\n",
    "\n",
    "## 1. Clean Web Page Text Using trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Extracted Text Preview:\n",
      "\n",
      "Physics > Physics Education\n",
      "[Submitted on 3 Feb 2024]\n",
      "Title:Uso de herramientas digitales matemáticas en la Educación Secundaria\n",
      "View PDF HTML (experimental)Abstract:Information and Community Technologies (ICT) are very present in our society nowadays and particularly in the educative field. In just two decades, we have passed from a learning based, in many cases, on the master lessons to one such that methodologies like the flipped classroom or the gamification are stronger than ever. Along this work, we have done a study to teachers and students with the main objective to compare the knowledge on digital tools, their use and their acceptation. We use WxMaxima and Geogebra in order to solve an exercise of \\textit{Evaluación de Bachillerato para el Acceso a la Universidad} (EBAU) related with Geometry, comparing their ins and outs with the manual solution. Finally, we expose some conclusions and some possible research lines about digital tools, as well as a proposition of an introducto\n"
     ]
    }
   ],
   "source": [
    "# ✅ Install dependencies if not already installed\n",
    "# !pip install trafilatura\n",
    "\n",
    "import trafilatura\n",
    "import requests\n",
    "\n",
    "# Example: An arXiv paper abstract page\n",
    "url = \"https://arxiv.org/abs/2404.00001\"\n",
    "\n",
    "# Step 1: Fetch raw HTML\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "# Step 2: Use Trafilatura to extract clean text\n",
    "downloaded_text = trafilatura.extract(html, include_comments=False, include_tables=False)\n",
    "\n",
    "# Step 3: Display the result\n",
    "print(\"📄 Extracted Text Preview:\\n\")\n",
    "print(downloaded_text[:1000])  # Show first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "trafilatura.extract() pulls main article content while removing headers, menus, and boilerplate.\n",
    "\n",
    "This works great on academic websites like arXiv, blog posts, or news articles.\n",
    "\n",
    "No need to write custom HTML parsers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: OCR – Convert Images to Text\n",
    "### Option A: Tesseract OCR (Offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might use the following install if the pytesseract is not installed\n",
    "# ! sudo apt-get update -y\n",
    "# ! sudo apt-get install -y tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/md/jx00px7j64jb171dzf32jybr0000gn/T/ipykernel_3985/3830433356.py\", line 2, in <module>\n",
      "    import pytesseract\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pytesseract/__init__.py\", line 2, in <module>\n",
      "    from .pytesseract import ALTONotSupported\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pytesseract/pytesseract.py\", line 42, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py\", line 52, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/md/jx00px7j64jb171dzf32jybr0000gn/T/ipykernel_3985/3830433356.py\", line 2, in <module>\n",
      "    import pytesseract\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pytesseract/__init__.py\", line 2, in <module>\n",
      "    from .pytesseract import ALTONotSupported\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pytesseract/pytesseract.py\", line 42, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py\", line 66, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/pc/Documents/cursor/ml course/practice/week3/test_data/image/image.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load and preprocess image (convert to grayscale)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./test_data/image/image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# grayscale\u001b[39;00m\n\u001b[1;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(image)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📄 Tesseract OCR Output (first 500 chars):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/PIL/Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/pc/Documents/cursor/ml course/practice/week3/test_data/image/image.png'"
     ]
    }
   ],
   "source": [
    "# Install: sudo apt install tesseract-ocr OR !pip install pytesseract Pillow\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess image (convert to grayscale)\n",
    "image = Image.open(\"./test_data/image/image.png\").convert(\"L\")  # grayscale\n",
    "text = pytesseract.image_to_string(image)\n",
    "\n",
    "print(\"📄 Tesseract OCR Output (first 500 chars):\")\n",
    "print(text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Surya OCR (Fast PyTorch-based layout-aware tool)\n",
    "https://github.com/VikParuchuri/surya\n",
    "\n",
    "### Usage\n",
    "To perform OCR on an image, PDF, or a folder containing them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Good for: simple single-column text, PDFs converted to images\n",
    "* Struggles with layout, math, or low-res scans \n",
    "    * As you can see from the image: \"Download Models\" has not been extreact out correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model vikp/surya_det3 on device mps with dtype torch.float16\n",
      "Loaded recognition model vikp/surya_rec2 on device mps with dtype torch.float16\n",
      "Detecting bboxes: 100%|███████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "Recognizing Text: 100%|███████████████████████████| 1/1 [00:11<00:00, 11.26s/it]\n",
      "Wrote results to /Users/scottlai/Library/Mobile Documents/com~apple~CloudDocs/Desktop/work/inferenceAI/Class3/results/image\n"
     ]
    }
   ],
   "source": [
    "! surya_ocr ./test_data/image/image.png --langs en --images --output_dir results/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "**DATA_PATH** is the path to your image, PDF, or folder.\n",
    "\n",
    "**--langs** specifies the language(s) for OCR (e.g., en for English).\n",
    "\n",
    "**--images** saves images of the pages and detected text lines (optional).\n",
    "\n",
    "**--output_dir** specifies the directory to save results.​\n",
    "\n",
    "This command will generate a results.json file containing the detected text and bounding boxes.​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Output Structure\n",
    "The **results.json** will have entries like:​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "  \"image\": [\n",
    "    {\n",
    "      \"text_lines\": [\n",
    "        {\n",
    "          \"polygon\": [\n",
    "            [\n",
    "              13,\n",
    "              48\n",
    "            ],\n",
    "            [\n",
    "              538,\n",
    "              51\n",
    "            ],\n",
    "            [\n",
    "              538,\n",
    "              87\n",
    "            ],\n",
    "            [\n",
    "              12,\n",
    "              84\n",
    "            ]\n",
    "          ],\n",
    "          \"confidence\": 0.9970703125,\n",
    "          \"text\": \"Llama 4: Leading intelligence.\",\n",
    "          \"bbox\": [\n",
    "            12,\n",
    "            48,\n",
    "            538,\n",
    "            87\n",
    "          ]\n",
    "        },\n",
    "        ...\n",
    "        {\n",
    "          \"polygon\": [\n",
    "            [\n",
    "              47,\n",
    "              364\n",
    "            ],\n",
    "            [\n",
    "              176,\n",
    "              364\n",
    "            ],\n",
    "            [\n",
    "              176,\n",
    "              378\n",
    "            ],\n",
    "            [\n",
    "              47,\n",
    "              378\n",
    "            ]\n",
    "          ],\n",
    "          \"confidence\": 0.9716796875,\n",
    "          \"text\": \"Download models\",\n",
    "          \"bbox\": [\n",
    "            47,\n",
    "            364,\n",
    "            176,\n",
    "            378\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"languages\": [\n",
    "        \"en\"\n",
    "      ],\n",
    "      \"image_bbox\": [\n",
    "        0,\n",
    "        0,\n",
    "        600,\n",
    "        471\n",
    "      ],\n",
    "      \"page\": 1\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or in python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model vikp/surya_det3 on device mps with dtype torch.float16\n",
      "Loaded recognition model vikp/surya_rec2 on device mps with dtype torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Llama 4: Leading intelligence.\n",
      "Confidence: 0.9970703125\n",
      "Polygon: [[13.0, 48.0], [538.0, 51.0], [538.0, 87.0], [12.0, 84.0]]\n",
      "\n",
      "Text: Unrivaled speed and efficiency.\n",
      "Confidence: 0.99462890625\n",
      "Polygon: [[12.0, 116.0], [564.0, 113.0], [565.0, 148.0], [13.0, 151.0]]\n",
      "\n",
      "Text: The most accessible and scalable generation of Llama is here.\n",
      "Confidence: 0.9990234375\n",
      "Polygon: [[13.0, 186.0], [565.0, 186.0], [565.0, 204.0], [13.0, 204.0]]\n",
      "\n",
      "Text: Native multimodality, mixture-of-experts models, super long\n",
      "Confidence: 0.99462890625\n",
      "Polygon: [[12.0, 214.0], [557.0, 212.0], [558.0, 230.0], [13.0, 231.0]]\n",
      "\n",
      "Text: context windows, step changes in performance, and\n",
      "Confidence: 0.99853515625\n",
      "Polygon: [[13.0, 240.0], [481.0, 240.0], [481.0, 258.0], [13.0, 258.0]]\n",
      "\n",
      "Text: unparalleled efficiency. All in easy-to-deploy sizes custom fit for\n",
      "Confidence: 0.9990234375\n",
      "Polygon: [[13.0, 268.0], [586.0, 268.0], [586.0, 285.0], [13.0, 285.0]]\n",
      "\n",
      "Text: how you want to use it.\n",
      "Confidence: 0.9765625\n",
      "Polygon: [[13.0, 295.0], [224.0, 295.0], [224.0, 312.0], [13.0, 312.0]]\n",
      "\n",
      "Text: Download models\n",
      "Confidence: 0.9716796875\n",
      "Polygon: [[47.0, 364.0], [176.0, 364.0], [176.0, 378.0], [47.0, 378.0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from surya.detection import DetectionPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(\"./test_data/image/image.png\")  # Replace with your image path\n",
    "langs = [\"en\"]  # Specify the language(s)\n",
    "\n",
    "# Initialize predictors\n",
    "detection_predictor = DetectionPredictor()\n",
    "recognition_predictor = RecognitionPredictor()\n",
    "\n",
    "# Perform OCR\n",
    "predictions = recognition_predictor([image], [langs], detection_predictor)\n",
    "\n",
    "# Display results with polygon coordinates\n",
    "for page in predictions:\n",
    "    for line in page.text_lines:\n",
    "        print(f\"Text: {line.text}\")\n",
    "        print(f\"Confidence: {line.confidence}\")\n",
    "        print(f\"Polygon: {line.polygon}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Good for: structured layouts like academic papers\n",
    "* Fast inference and easy to integrate with PDF workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: OpenAI GPT-4o Vision OCR (Highly Accurate & Multicolumn)\n",
    "don't forget to add you `OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Llama 4: Leading intelligence. Unrivaled speed and efficiency.**\n",
      "\n",
      "The most accessible and scalable generation of Llama is here. Native multimodality, mixture-of-experts models, super long context windows, step changes in performance, and unparalleled efficiency. All in easy-to-deploy sizes custom fit for how you want to use it.\n",
      "\n",
      "**Download models**\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "def vision_extract(b64_image, prompt, api_key):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64_image}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        \"max_tokens\": 3000\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Load image and run GPT-4o OCR\n",
    "with open(\"test_data/image/image.png\", \"rb\") as f:\n",
    "    b64_img = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Use your actual API key here\n",
    "result = vision_extract(b64_img, \"Extract all the readable text from this document.\", api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "print(result[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Good for: complex, multi-column documents and natural layout reasoning\n",
    "* Great fallback when you need accuracy over speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Automatic Speech Recognition (ASR)\n",
    "### Option A: Whisper by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! brew install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Whisper Transcription:\n",
      " So we pay for that, they didn't, you know, there are some people, they said, it's on, Kren the Benzo, instead of caught in a musical, I was just not talking about your own interest and just turning child, that's the...\n"
     ]
    }
   ],
   "source": [
    "# Install: pip install openai-whisper\n",
    "import whisper\n",
    "\n",
    "# Load model\n",
    "model = whisper.load_model(\"base\")  # or \"small\", \"medium\", \"large\"\n",
    "\n",
    "# Transcribe audio\n",
    "result = model.transcribe(\"./test_data/audio/sample-1.mp3\")\n",
    "print(\"📄 Whisper Transcription:\")\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Great for: balanced speed and accuracy\n",
    "* Supports many audio formats: mp3, wav, m4a, webm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Faster-Whisper (Fast & Lightweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Faster-Whisper Transcription:\n",
      "[0.00 - 4.00]  If we pay for that, they don't, you know, there are some people who say that it's on.\n",
      "[4.00 - 8.00]  Cren the Benzo instead of caught in a musical or there's not a story of what you're interested in.\n",
      "[8.00 - 10.00]  It's just turning child, that's the...\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Load model with float16 for speed\n",
    "model = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\")  # For CPUs\n",
    "\n",
    "# Transcribe\n",
    "segments, _ = model.transcribe(\"./test_data/audio/sample-1.mp3\")\n",
    "\n",
    "print(\"📄 Faster-Whisper Transcription:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment.start:.2f} - {segment.end:.2f}] {segment.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optimized for GPU or even CPU \n",
    "* Useful when batch-processing long audio datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pretraining Data Cleaning Pipeline\n",
    "### Step 1: Remove duplicates using MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "def minhash_deduplication(texts, threshold=0.7):\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=128)\n",
    "    unique_texts = []\n",
    "    for i, doc in enumerate(texts):\n",
    "        m = MinHash(num_perm=128)\n",
    "        for word in set(doc.split()):\n",
    "            m.update(word.encode('utf8'))\n",
    "        if not lsh.query(m):\n",
    "            lsh.insert(f\"doc{i}\", m)\n",
    "            unique_texts.append(doc)\n",
    "    return unique_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter for language and strip HTML noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages/python_autocite-0.0.4-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langdetect in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langdetect) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html_and_filter_lang(texts, lang='en'):\n",
    "    filtered = []\n",
    "    for txt in texts:\n",
    "        txt = BeautifulSoup(txt, 'html.parser').get_text()\n",
    "        try:\n",
    "            if detect(txt.strip()) == lang:\n",
    "                filtered.append(txt.strip())\n",
    "        except:\n",
    "            continue\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Strip PII using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strip_pii(text):\n",
    "    text = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '[EMAIL]', text)\n",
    "    text = re.sub(r'\\b\\d{12,19}\\b', '[CREDIT_CARD]', text)\n",
    "    text = re.sub(r'\\b(?:\\d{3}-){2}\\d{4}\\b', '[PHONE]', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Remove repetitive n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def remove_repetitive_ngrams(text, n=3, threshold=3):\n",
    "    words = text.split()\n",
    "    ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "    counts = Counter(ngrams)\n",
    "    repetitive = [ngram for ngram, count in counts.items() if count >= threshold]\n",
    "\n",
    "    for phrase in repetitive:\n",
    "        # regex-safe version of the phrase\n",
    "        escaped_phrase = re.escape(phrase)\n",
    "        # match the phrase repeated 2+ times with optional whitespace\n",
    "        text = re.sub(rf'(?:{escaped_phrase}\\s*){{{threshold},}}', phrase + ' ', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: prepare for the text data\n",
    "load the Fake_pretraining_Texts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Hello! Contact us at support@data.org or call ...\n",
      "1    Hola! Este artículo está completamente en espa...\n",
      "2    <html><body><div><h1>Breaking News</h1><p>This...\n",
      "3    Buy now! Best product ever. Best product ever....\n",
      "4    Python 3.14 introduces several improvements in...\n",
      "5    Python 3.14 introduces several improvements in...\n",
      "6    <div>For inquiries, email jane_doe@example.com...\n",
      "7    Large Language Models are transforming the AI ...\n",
      "8                  这是一个包含有用技术信息的中文段落。电话号码：010-12345678\n",
      "9    Buy now! Best product ever. Best product ever....\n",
      "Name: Raw Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fake_texts = pd.read_csv(\"test_data/data/Fake_Pretraining_Texts.csv\")\n",
    "raw_dataset = fake_texts[\"Raw Text\"]\n",
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Apply the Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! Contact us at support@data.org or call 123-456-7890. Your credit card 4111111111111111 was declined. This message is intended only for the recipient. Visit our site for more.',\n",
       " 'Breaking NewsThis is a major event!Contact us',\n",
       " 'Buy now! Best product ever. Best product ever. Best product ever.',\n",
       " 'Python 3.14 introduces several improvements including better error messages. Learn more on the official site.',\n",
       " 'Python 3.14 introduces several improvements including better error messages. Learn more on the official docs.',\n",
       " 'For inquiries, email jane_doe@example.com or visit our site. Card number: 378282246310005.',\n",
       " 'Large Language Models are transforming the AI landscape with few-shot capabilities.',\n",
       " 'Buy now! Best product ever. Best product ever. Best product ever.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Remove HTML + Language Filter\n",
    "step1 = clean_html_and_filter_lang(raw_dataset)\n",
    "display(step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! Contact us at support@data.org or call 123-456-7890. Your credit card 4111111111111111 was declined. This message is intended only for the recipient. Visit our site for more.',\n",
       " 'Breaking NewsThis is a major event!Contact us',\n",
       " 'Buy now! Best product ever. Best product ever. Best product ever.',\n",
       " 'Python 3.14 introduces several improvements including better error messages. Learn more on the official site.',\n",
       " 'For inquiries, email jane_doe@example.com or visit our site. Card number: 378282246310005.',\n",
       " 'Large Language Models are transforming the AI landscape with few-shot capabilities.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Deduplicate Paragraphs\n",
    "step2 = minhash_deduplication(step1)\n",
    "display(step2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! Contact us at [EMAIL] or call [PHONE]. Your credit card [CREDIT_CARD] was declined. This message is intended only for the recipient. Visit our site for more.',\n",
       " 'Breaking NewsThis is a major event!Contact us',\n",
       " 'Buy now! Best product ever. Best product ever. Best product ever.',\n",
       " 'Python 3.14 introduces several improvements including better error messages. Learn more on the official site.',\n",
       " 'For inquiries, email [EMAIL] or visit our site. Card number: [CREDIT_CARD].',\n",
       " 'Large Language Models are transforming the AI landscape with few-shot capabilities.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Strip PII\n",
    "step3 = [strip_pii(t) for t in step2]\n",
    "display(step3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! Contact us at [EMAIL] or call [PHONE]. Your credit card [CREDIT_CARD] was declined. This message is intended only for the recipient. Visit our site for more.',\n",
       " 'Breaking NewsThis is a major event!Contact us',\n",
       " 'Buy now! Best product ever.',\n",
       " 'Python 3.14 introduces several improvements including better error messages. Learn more on the official site.',\n",
       " 'For inquiries, email [EMAIL] or visit our site. Card number: [CREDIT_CARD].',\n",
       " 'Large Language Models are transforming the AI landscape with few-shot capabilities.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Remove Repetitive N-grams\n",
    "cleaned_data = [remove_repetitive_ngrams(t) for t in step3]\n",
    "display(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset sample:\n",
      "--- Article 1 ---\n",
      "Hello! Contact us at [EMAIL] or call [PHONE]. Your credit card [CREDIT_CARD] was declined. This message is intended only for the recipient. Visit our site for more.\n",
      "--- Article 2 ---\n",
      "Breaking NewsThis is a major event!Contact us\n",
      "--- Article 3 ---\n",
      "Buy now! Best product ever.\n",
      "--- Article 4 ---\n",
      "Python 3.14 introduces several improvements including better error messages. Learn more on the official site.\n",
      "--- Article 5 ---\n",
      "For inquiries, email [EMAIL] or visit our site. Card number: [CREDIT_CARD].\n",
      "--- Article 6 ---\n",
      "Large Language Models are transforming the AI landscape with few-shot capabilities.\n"
     ]
    }
   ],
   "source": [
    "# Done!\n",
    "print(\"✅ Cleaned dataset sample:\")\n",
    "for idx, text in enumerate(cleaned_data):\n",
    "    print(f\"--- Article {idx + 1} ---\")\n",
    "    print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
